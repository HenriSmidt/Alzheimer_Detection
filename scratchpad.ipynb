{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/4bf7qdjd6k9b38g7jlnrcf580000gn/T/ipykernel_30646/2326577472.py:46: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  rows = self.df.loc[(id, slice_num)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import lightning.pytorch as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, dataframe, slice_number, transform=None):\n",
    "        self.df = dataframe.set_index(['ID', 'slice_number'])\n",
    "        self.slice_number = slice_number\n",
    "        self.transform = transform\n",
    "        self.resize = transforms.Resize((224, 224))  # Ensure images are resized to 224x224\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index.unique())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id, slice_num = self.df.index.unique()[idx]\n",
    "        images = []\n",
    "        for offset in (-1, 0, 1):\n",
    "            slice_path = self.get_random_path(id, slice_num + offset)\n",
    "            image = Image.open(slice_path).convert('L')\n",
    "            image = self.resize(image)  # Resize the image\n",
    "            image = np.array(image)\n",
    "            images.append(image)\n",
    "        \n",
    "        # Stack to create a 3-channel image\n",
    "        image_stack = np.stack(images, axis=-1)  # Shape will be (H, W, C)\n",
    "        image_stack = torch.tensor(image_stack).permute(2, 0, 1)  # Convert to (C, H, W) tensor\n",
    "        \n",
    "        # Normalize the image stack to [0, 1]\n",
    "        image_stack = image_stack.float() / 255.0\n",
    "        \n",
    "        if self.transform:\n",
    "            image_stack = self.transform(image_stack)\n",
    "            \n",
    "        return image_stack\n",
    "\n",
    "    def get_random_path(self, id, slice_num):\n",
    "        try:\n",
    "            rows = self.df.loc[(id, slice_num)]\n",
    "            if not rows.empty:\n",
    "                # Randomly select between masked and unmasked if available\n",
    "                row = rows.sample(n=1)\n",
    "                return row['path'].values[0]\n",
    "            else:\n",
    "                # If the specific slice_num doesn't exist, default to the original slice\n",
    "                return self.df.loc[(id, self.slice_number)].sample(n=1)['path'].values[0]\n",
    "        except KeyError:\n",
    "            # In case the slice is completely unavailable, use the fallback slice\n",
    "            return self.df.loc[(id, self.slice_number)].sample(n=1)['path'].values[0]\n",
    "\n",
    "\n",
    "class MRIImageDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_path, batch_size=32, slice_number=87):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.slice_number = slice_number\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        data = pd.read_csv(self.data_path)\n",
    "        train_ids, test_ids = train_test_split(data['ID'].unique(), test_size=0.2, random_state=42)\n",
    "\n",
    "        train_df = data[data['ID'].isin(train_ids)]\n",
    "        test_df = data[data['ID'].isin(test_ids)]\n",
    "\n",
    "        self.train_dataset = MRIDataset(train_df, self.slice_number, transform=self.transform)\n",
    "        self.test_dataset = MRIDataset(test_df, self.slice_number, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Usage\n",
    "data_module = MRIImageDataModule(data_path='Data/metadata_for_preprocessed_files.csv', slice_number=63)\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "for batch in train_loader:\n",
    "    # Each batch should have the dimensions [batch_size, channels, height, width]\n",
    "    print(batch.shape)  # Should output torch.Size([batch_size, 3, 224, 224])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['OAS1_0002_MR1', 'OAS1_0003_MR1'], dtype=object),\n",
       " array(['OAS1_0001_MR1'], dtype=object),\n",
       " 3,\n",
       " 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = {\n",
    "    'ID': ['OAS1_0001_MR1', 'OAS1_0001_MR1', 'OAS1_0001_MR1', 'OAS1_0002_MR1', 'OAS1_0002_MR1', 'OAS1_0003_MR1'],\n",
    "    'slice_number': [62, 63, 64, 63, 64, 63],\n",
    "    'path': [\n",
    "        'Data/OASIS_Extracted/OAS1_0001/OAS1_0001_MR1_mpr_n4_anon_111_t88_gfc_slice_62.jpeg',\n",
    "        'Data/OASIS_Extracted/OAS1_0001/OAS1_0001_MR1_mpr_n4_anon_111_t88_gfc_slice_63.jpeg',\n",
    "        'Data/OASIS_Extracted/OAS1_0001/OAS1_0001_MR1_mpr_n4_anon_111_t88_gfc_slice_64.jpeg',\n",
    "        'Data/OASIS_Extracted/OAS1_0002/OAS1_0002_MR1_mpr_n4_anon_111_t88_gfc_slice_63.jpeg',\n",
    "        'Data/OASIS_Extracted/OAS1_0002/OAS1_0002_MR1_mpr_n4_anon_111_t88_gfc_slice_64.jpeg',\n",
    "        'Data/OASIS_Extracted/OAS1_0003/OAS1_0003_MR1_mpr_n4_anon_111_t88_gfc_slice_63.jpeg'\n",
    "    ],\n",
    "    'CDR': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    'is_masked': [True, False, True, False, True, False]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "train_ids, test_ids = train_test_split(df['ID'].unique(), test_size=0.2, random_state=42)\n",
    "train_df = df[df['ID'].isin(train_ids)]\n",
    "test_df = df[df['ID'].isin(test_ids)]\n",
    "\n",
    "train_size = len(train_df)\n",
    "test_size = len(test_df)\n",
    "\n",
    "train_ids, test_ids, train_size, test_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>slice_number</th>\n",
       "      <th>path</th>\n",
       "      <th>CDR</th>\n",
       "      <th>is_masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OAS1_0002_MR1</td>\n",
       "      <td>63</td>\n",
       "      <td>Data/OASIS_Extracted/OAS1_0002/OAS1_0002_MR1_m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OAS1_0002_MR1</td>\n",
       "      <td>64</td>\n",
       "      <td>Data/OASIS_Extracted/OAS1_0002/OAS1_0002_MR1_m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OAS1_0003_MR1</td>\n",
       "      <td>63</td>\n",
       "      <td>Data/OASIS_Extracted/OAS1_0003/OAS1_0003_MR1_m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID  slice_number  \\\n",
       "3  OAS1_0002_MR1            63   \n",
       "4  OAS1_0002_MR1            64   \n",
       "5  OAS1_0003_MR1            63   \n",
       "\n",
       "                                                path  CDR  is_masked  \n",
       "3  Data/OASIS_Extracted/OAS1_0002/OAS1_0002_MR1_m...  0.0      False  \n",
       "4  Data/OASIS_Extracted/OAS1_0002/OAS1_0002_MR1_m...  0.0       True  \n",
       "5  Data/OASIS_Extracted/OAS1_0003/OAS1_0003_MR1_m...  0.0      False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l5/4bf7qdjd6k9b38g7jlnrcf580000gn/T/ipykernel_31166/2985792169.py:134: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  rows = self.df.loc[(id, slice_num)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Unnamed: 0 M/F Hand  Age  Educ  SES  MMSE  CDR  \\\n",
      "ID            slice_number                                                   \n",
      "OAS1_0410_MR1 62                   372   F    R   23   NaN  NaN   NaN  0.0   \n",
      "              62                   372   F    R   23   NaN  NaN   NaN  0.0   \n",
      "\n",
      "                            eTIV  nWBV    ASF  Delay  \\\n",
      "ID            slice_number                             \n",
      "OAS1_0410_MR1 62            1507  0.87  1.165    NaN   \n",
      "              62            1507  0.87  1.165    NaN   \n",
      "\n",
      "                                                                         path  \\\n",
      "ID            slice_number                                                      \n",
      "OAS1_0410_MR1 62            Data/OASIS_Extracted/OAS1_0410/OAS1_0410_MR1_m...   \n",
      "              62            Data/OASIS_Extracted/OAS1_0410/OAS1_0410_MR1_m...   \n",
      "\n",
      "                            is_masked  \n",
      "ID            slice_number             \n",
      "OAS1_0410_MR1 62                False  \n",
      "              62                 True  \n",
      "                            Unnamed: 0 M/F Hand  Age  Educ  SES  MMSE  CDR  \\\n",
      "ID            slice_number                                                   \n",
      "OAS1_0410_MR1 62                   372   F    R   23   NaN  NaN   NaN  0.0   \n",
      "\n",
      "                            eTIV  nWBV    ASF  Delay  \\\n",
      "ID            slice_number                             \n",
      "OAS1_0410_MR1 62            1507  0.87  1.165    NaN   \n",
      "\n",
      "                                                                         path  \\\n",
      "ID            slice_number                                                      \n",
      "OAS1_0410_MR1 62            Data/OASIS_Extracted/OAS1_0410/OAS1_0410_MR1_m...   \n",
      "\n",
      "                            is_masked  \n",
      "ID            slice_number             \n",
      "OAS1_0410_MR1 62                 True  \n",
      "ID             slice_number\n",
      "OAS1_0410_MR1  62              Data/OASIS_Extracted/OAS1_0410/OAS1_0410_MR1_m...\n",
      "Name: path, dtype: object\n",
      "Data/OASIS_Extracted/OAS1_0410/OAS1_0410_MR1_mpr_n3_anon_111_t88_masked_gfc_slice_62.jpeg\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. \n",
      "\u001b[1;31mBitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. \n",
      "\u001b[1;31mKlicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. \n",
      "\u001b[1;31mWeitere Informationen finden Sie unter Jupyter <a href='command:jupyter.viewOutput'>Protokoll</a>."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import lightning.pytorch as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "# class MRIDataset(Dataset):\n",
    "#     def __init__(self, dataframe, slice_number, transform=None):\n",
    "#         self.df = dataframe.set_index(['ID', 'slice_number'])\n",
    "#         self.slice_number = slice_number\n",
    "#         self.transform = transform\n",
    "#         self.resize = transforms.Resize((224, 224))  # Ensure images are resized to 224x224 # TODO: better to have an assert to save time, since data should be this size already?\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.df.index.unique())\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         id, slice_num = self.df.index.unique()[idx]\n",
    "#         images = []\n",
    "#         for offset in (-1, 0, 1):\n",
    "#             slice_path = self.get_random_path(id, slice_num + offset)\n",
    "#             image = Image.open(slice_path).convert('L')\n",
    "#             image = np.array(image)\n",
    "#             images.append(image)\n",
    "        \n",
    "#         # Stack to create a 3-channel image\n",
    "#         image_stack = np.stack(images, axis=-1)  # Shape will be (H, W, C)\n",
    "#         image_stack = torch.tensor(image_stack).permute(2, 0, 1)  # Convert to (C, H, W) tensor\n",
    "        \n",
    "#         # Normalize the image stack to [0, 1]\n",
    "#         image_stack = image_stack.float() / 255.0 # TODO: check if images were already normalized and resized to 224 by 224\n",
    "        \n",
    "#         if self.transform:\n",
    "#             image_stack = self.transform(image_stack)\n",
    "            \n",
    "#         return image_stack\n",
    "\n",
    "#     def get_random_path(self, id, slice_num):\n",
    "#         try:\n",
    "#             rows = self.df.loc[(id, slice_num)]\n",
    "#             if not rows.empty:\n",
    "#                 # Randomly select between masked and unmasked if available\n",
    "#                 row = rows.sample(n=1)\n",
    "#                 return row['path'].values[0]\n",
    "#             else:\n",
    "#                 # If the specific slice_num doesn't exist, default to the original slice\n",
    "#                 return self.df.loc[(id, self.slice_number)].sample(n=1)['path'].values[0]\n",
    "#         except KeyError:\n",
    "#                print(f\"KeyError: The slice number {slice_num} or id {id} does not exist in the Data.\")\n",
    "#         return None\n",
    "\n",
    "# class MRIImageDataModule(pl.LightningDataModule):\n",
    "#     def __init__(self, data_path, batch_size=32, slice_number=87):\n",
    "#         super().__init__()\n",
    "#         self.data_path = data_path\n",
    "#         self.batch_size = batch_size\n",
    "#         self.slice_number = slice_number\n",
    "\n",
    "#     def setup(self, stage=None):\n",
    "#         data = pd.read_csv(self.data_path)\n",
    "#         train_ids, test_ids = train_test_split(data['ID'].unique(), test_size=0.2, random_state=42)\n",
    "\n",
    "#         train_df = data[data['ID'].isin(train_ids)]\n",
    "#         test_df = data[data['ID'].isin(test_ids)]\n",
    "\n",
    "#         self.train_dataset = MRIDataset(train_df, self.slice_number)\n",
    "#         self.test_dataset = MRIDataset(test_df, self.slice_number)\n",
    "\n",
    "#     def train_dataloader(self):\n",
    "#         return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Usage\n",
    "# data_module = MRIImageDataModule(data_path='Data/metadata_for_preprocessed_files.csv', slice_number=63)\n",
    "# data_module.setup()\n",
    "# train_loader = data_module.train_dataloader()\n",
    "# for batch in train_loader:\n",
    "#     # Each batch should have the dimensions [batch_size, channels, height, width]\n",
    "#     print(batch.shape)  # Should output torch.Size([batch_size, 3, 224, 224])\n",
    "#     break\n",
    "\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, dataframe, slice_number, transform=None):\n",
    "        self.slice_number = slice_number\n",
    "        self.transform = transform\n",
    "        self.df = dataframe\n",
    "        self.valid_ids = dataframe[dataframe['slice_number'] == slice_number]['ID'].unique()\n",
    "        self.df = self.df[self.df['ID'].isin(self.valid_ids)].set_index(['ID', 'slice_number'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id = self.valid_ids[idx]\n",
    "        images = []\n",
    "        \n",
    "        for offset in (-1, 0, 1):\n",
    "            slice_path = self.get_random_path(id, self.slice_number + offset)\n",
    "            image = Image.open(slice_path).convert('L')\n",
    "            image = np.array(image)\n",
    "            images.append(image)\n",
    "        \n",
    "        # Stack to create a 3-channel image\n",
    "        image_stack = np.stack(images, axis=-1)  # Shape will be (H, W, C)\n",
    "        image_stack = torch.tensor(image_stack).permute(2, 0, 1)  # Convert to (C, H, W) tensor\n",
    "        \n",
    "        # Normalize the image stack to [0, 1]\n",
    "        image_stack = image_stack.float() / 255.0 #TODO: check if images are already normalized and sized to 224 224\n",
    "        \n",
    "        if self.transform:\n",
    "            image_stack = self.transform(image_stack)\n",
    "            \n",
    "        return image_stack\n",
    "    \n",
    "    def get_random_path(self, id, slice_num):\n",
    "        try:\n",
    "            rows = self.df.loc[(id, slice_num)]\n",
    "            if not rows.empty:\n",
    "                # Randomly select between masked and unmasked if available\n",
    "                row = rows.sample(n=1)\n",
    "                return row['path'].values[0]\n",
    "            else:\n",
    "                # If the specific slice_num doesn't exist, default to the original slice\n",
    "                return self.df.loc[(id, self.slice_number)].sample(n=1)['path'].values[0]\n",
    "        except KeyError:\n",
    "            # In case the slice is completely unavailable, use the fallback slice\n",
    "            try: \n",
    "                return self.df.loc[(id, self.slice_number)].sample(n=1)['path'].values[0]\n",
    "            except KeyError: #                \n",
    "                print(f\"KeyError: The slice number {self.slice_number} or id {id} does not exist in the Data.\")\n",
    "        return None\n",
    "\n",
    "class MRIImageDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_path, batch_size=32, slice_number=87):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.slice_number = slice_number\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        data = pd.read_csv(self.data_path)\n",
    "        \n",
    "        # Filter to only include IDs with the specified slice_number\n",
    "        data = data[data['slice_number'].isin([self.slice_number - 1, self.slice_number, self.slice_number + 1])]\n",
    "\n",
    "        train_ids, test_ids = train_test_split(data['ID'].unique(), test_size=0.2, random_state=42)\n",
    "\n",
    "        train_df = data[data['ID'].isin(train_ids)]\n",
    "        test_df = data[data['ID'].isin(test_ids)]\n",
    "\n",
    "        self.train_dataset = MRIDataset(train_df, self.slice_number)\n",
    "        self.test_dataset = MRIDataset(test_df, self.slice_number)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "# Usage example\n",
    "# data_module = MRIImageDataModule(data_path='Data/metadata_for_preprocessed_files.csv', slice_number=63)\n",
    "# data_module.setup()\n",
    "# train_loader = data_module.train_dataloader()\n",
    "# for batch in train_loader:\n",
    "#     print(batch.shape)  # Should output torch.Size([batch_size, 3, 224, 224])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alzheimer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
