{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/henrismidt/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import LoginCredentials\n",
    "import wandb\n",
    "\n",
    "authenticator = LoginCredentials()\n",
    "\n",
    "wandb.login(key=authenticator.wandb_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 0n5egokx\n",
      "Sweep URL: https://wandb.ai/finnhenri-smidt/Alzheimer-Detection/sweeps/0n5egokx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import MobileViTImageProcessor\n",
    "import wandb\n",
    "\n",
    "from dataset import MRIImageDataModule, MRIDataset\n",
    "from models import MobileViTLightning, EfficientNetBaseline\n",
    "from utils import get_best_device, LoginCredentials, set_reproducibility\n",
    "from sampler import WeightedRandomSampler\n",
    "\n",
    "from datetime import datetime\n",
    "import lightning.pytorch as pl\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report, confusion_matrix\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "set_reproducibility(42)\n",
    "\n",
    "wandb.finish()  # Make sure previous sessions are finished\n",
    "\n",
    "\n",
    "csv_path = \"Data/metadata_for_preprocessed_files.csv\"\n",
    "\n",
    "# Define sweep configuration\n",
    "sweep_config = {\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"name\": \"val_loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"model_name\": {\n",
    "            \"values\": [\"MobileVit\", \"efficientnet-b2\"]\n",
    "        },  # [\"efficientnet-b2\"\"MobileVit\", \"efficientnet-b0\", \"efficientnet-b2\", \"efficientnet-b5\"]\n",
    "        \"slice_number\": {\n",
    "            \"values\": [\n",
    "                \"65\",\n",
    "                # \"86\",\n",
    "                # \"56\",\n",
    "                # \"95\",\n",
    "                # \"62\",\n",
    "                # \"35\",\n",
    "                # \"59\",\n",
    "                # \"74\",\n",
    "                # \"80\",\n",
    "                # \"134\",\n",
    "            ]  # ['65', '86', '56', '95', '62', '35', '59', '74', '80', '134', '41', '104', '101', '116', '68', '89', '107', '92', '71', '77', '113', '23', '98', '110', '131', '128', '125', '122', '119', '20', '83', '53', '50', '47', '44', '38', '32', '29', '26', '137']\n",
    "        },\n",
    "        \"learning_rate\": {\"values\": [0.00001]},\n",
    "        \"batch_size\": {\"values\": [40]},\n",
    "        \"epochs\": {\"values\": [60]},\n",
    "        \"sampling_strategy\": {\"values\": ['log']}, #'inverse', 'sqrt',\n",
    "        \"smoothing\": {\"values\": [10]}, #10 for mobilevit, 0 for efficientnet\n",
    "        \"self_distillation_alpha\": {\"values\": [0.3, 0.5, 0.7]},\n",
    "        \"self_distillation_temperature\": {\"values\": [1, 3, 7]}\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=\"Alzheimer-Detection\")\n",
    "\n",
    "def load_soft_labels(slice_number, model_name):\n",
    "    soft_labels_path = f\"soft_labels/{model_name}/soft_labels_slice_{slice_number}.pkl\"\n",
    "    if os.path.exists(soft_labels_path):\n",
    "        with open(soft_labels_path, 'rb') as f:\n",
    "            soft_labels = pickle.load(f)\n",
    "    else:\n",
    "        soft_labels = None\n",
    "    return soft_labels\n",
    "\n",
    "\n",
    "# Define the training function\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        device = get_best_device()\n",
    "\n",
    "        if config.model_name == \"MobileVit\":\n",
    "            # Load the preprocessor\n",
    "            model_ckpt = \"apple/mobilevit-small\"\n",
    "            processor = MobileViTImageProcessor.from_pretrained(model_ckpt)\n",
    "\n",
    "            def transform(image):\n",
    "                # Use MobileViTImageProcessor for preprocessing\n",
    "                return processor(image, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)\n",
    "\n",
    "            model = MobileViTLightning(model_ckpt=model_ckpt, num_labels=4, self_distillation_alpha=config.self_distillation_alpha, self_distillation_temperature=config.self_distillation_temperature)\n",
    "\n",
    "        elif config.model_name.startswith(\"efficientnet\"):\n",
    "            transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "            # transform = None\n",
    "            model = EfficientNetBaseline(\n",
    "                model_name=config.model_name, lr=config.learning_rate, self_distillation_alpha=config.self_distillation_alpha, self_distillation_temperature=config.self_distillation_temperature\n",
    "            )\n",
    "\n",
    "        # Load soft labels\n",
    "        soft_labels = load_soft_labels(int(config.slice_number), config.model_name)\n",
    "\n",
    "        data_module = MRIImageDataModule(\n",
    "            csv_path,\n",
    "            slice_number=int(config.slice_number),\n",
    "            transform=transform,\n",
    "            batch_size=config.batch_size,\n",
    "            num_workers=0,\n",
    "            soft_labels=soft_labels,\n",
    "        )\n",
    "        data_module.setup()\n",
    "        train_loader = data_module.train_dataloader(sampling_strategy=config.sampling_strategy, smoothing=config.smoothing)\n",
    "        val_loader = data_module.val_dataloader()\n",
    "        test_loader = data_module.test_dataloader()\n",
    "\n",
    "        wandb_logger = WandbLogger()\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=f\"model_checkpoints/student_models/{config.model_name}\",\n",
    "            filename=f\"slice_number_{config.slice_number}_sd_alpha_{config.self_distillation_alpha}_sd_temp_{config.self_distillation_temperature}\",\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "        )\n",
    "\n",
    "        trainer = L.Trainer(\n",
    "            max_epochs=config.epochs,\n",
    "            devices=\"auto\",\n",
    "            accelerator=\"auto\",\n",
    "            logger=wandb_logger,\n",
    "            callbacks=[checkpoint_callback],\n",
    "            log_every_n_steps=24,\n",
    "        )\n",
    "\n",
    "        trainer.fit(\n",
    "            model=model, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    "        )\n",
    "\n",
    "        # Load best model for testing\n",
    "        best_model_path = checkpoint_callback.best_model_path\n",
    "        if config.model_name == \"MobileVit\":\n",
    "            model_ckpt = \"apple/mobilevit-small\"\n",
    "            best_model = MobileViTLightning.load_from_checkpoint(\n",
    "                best_model_path, model_ckpt=model_ckpt, num_labels=4\n",
    "            )\n",
    "\n",
    "        elif config.model_name.startswith(\"efficientnet\"):\n",
    "            best_model = EfficientNetBaseline.load_from_checkpoint(\n",
    "                best_model_path,\n",
    "                model_name=config.model_name,\n",
    "                num_classes=4,\n",
    "            )\n",
    "\n",
    "\n",
    "        # Evaluate on test set\n",
    "        best_model = best_model.to(device)\n",
    "        best_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_ids = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs, labels, age, id = batch\n",
    "                inputs = inputs.to(device).float()\n",
    "                outputs = best_model(inputs)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_ids.extend(id)\n",
    "\n",
    "            # Calculate metrics\n",
    "            f1_weighted = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "            f1_individual = f1_score(all_labels, all_preds, average=None)\n",
    "            precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
    "            recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
    "            conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "            classification_rep = classification_report(all_labels, all_preds, output_dict=True)\n",
    "\n",
    "            # Log metrics to wandb\n",
    "            wandb.log({\n",
    "                \"test_f1_weighted\": f1_weighted,\n",
    "                \"test_f1_individual\": f1_individual,\n",
    "                \"test_precision\": precision,\n",
    "                \"test_recall\": recall,\n",
    "                \"confusion_matrix\": conf_matrix,\n",
    "                \"classification_report\": classification_rep\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "# Run the sweep\n",
    "# wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vr4tjz1p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: MobileVit\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsampling_strategy: log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tself_distillation_alpha: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tself_distillation_temperature: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tslice_number: 65\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsmoothing: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc90d47f42b4d198634ab72381eda15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011169073611111142, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/henrismidt/Documents/Informatik/Master/Alzheimer_Detection/wandb/run-20240609_163837-vr4tjz1p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/finnhenri-smidt/Alzheimer-Detection/runs/vr4tjz1p' target=\"_blank\">trim-sweep-1</a></strong> to <a href='https://wandb.ai/finnhenri-smidt/Alzheimer-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/finnhenri-smidt/Alzheimer-Detection/sweeps/0n5egokx' target=\"_blank\">https://wandb.ai/finnhenri-smidt/Alzheimer-Detection/sweeps/0n5egokx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/finnhenri-smidt/Alzheimer-Detection' target=\"_blank\">https://wandb.ai/finnhenri-smidt/Alzheimer-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/finnhenri-smidt/Alzheimer-Detection/sweeps/0n5egokx' target=\"_blank\">https://wandb.ai/finnhenri-smidt/Alzheimer-Detection/sweeps/0n5egokx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/finnhenri-smidt/Alzheimer-Detection/runs/vr4tjz1p' target=\"_blank\">https://wandb.ai/finnhenri-smidt/Alzheimer-Detection/runs/vr4tjz1p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of MobileViTForImageClassification were not initialized from the model checkpoint at apple/mobilevit-small and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 640]) in the checkpoint and torch.Size([4, 640]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\n",
      "  | Name         | Type                            | Params\n",
      "-----------------------------------------------------------------\n",
      "0 | model        | MobileViTForImageClassification | 4.9 M \n",
      "1 | criterion    | CrossEntropyLoss                | 0     \n",
      "2 | kd_criterion | KLDivLoss                       | 0     \n",
      "-----------------------------------------------------------------\n",
      "4.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 M     Total params\n",
      "19.761    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9232180915ea4297a652f781073a6634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=24). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f269dd7a13b4d96b12c19dcb59dcbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/l5/4bf7qdjd6k9b38g7jlnrcf580000gn/T/ipykernel_51213/3298305049.py\", line 142, in train\n",
      "    trainer.fit(\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py\", line 987, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py\", line 1033, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 212, in advance\n",
      "    batch, _, __ = next(data_fetcher)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/fetchers.py\", line 133, in __next__\n",
      "    batch = super().__next__()\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/fetchers.py\", line 60, in __next__\n",
      "    batch = next(self.iterator)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/utilities/combined_loader.py\", line 78, in __next__\n",
      "    out[i] = next(self.iterators[i])\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/Users/henrismidt/Documents/Informatik/Master/Alzheimer_Detection/dataset.py\", line 69, in __getitem__\n",
      "    item['soft_labels'] = torch.tensor(self.soft_labels[id]).float()\n",
      "KeyError: 'OAS1_0038_MR1'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd0958fbd704f0b8ea85ecec424e586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/l5/4bf7qdjd6k9b38g7jlnrcf580000gn/T/ipykernel_51213/3298305049.py\", line 142, in train\n",
      "    trainer.fit(\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py\", line 987, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/trainer/trainer.py\", line 1033, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 212, in advance\n",
      "    batch, _, __ = next(data_fetcher)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/fetchers.py\", line 133, in __next__\n",
      "    batch = super().__next__()\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/loops/fetchers.py\", line 60, in __next__\n",
      "    batch = next(self.iterator)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/utilities/combined_loader.py\", line 341, in __next__\n",
      "    out = next(self._iterator)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/lightning/pytorch/utilities/combined_loader.py\", line 78, in __next__\n",
      "    out[i] = next(self.iterators[i])\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/Users/henrismidt/Documents/Informatik/Master/Alzheimer_Detection/dataset.py\", line 69, in __getitem__\n",
      "    item['soft_labels'] = torch.tensor(self.soft_labels[id]).float()\n",
      "KeyError: 'OAS1_0038_MR1'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 2352, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 2608, in _on_finish\n",
      "    _ = exit_handle.wait(timeout=-1, on_progress=self._on_progress_exit)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py\", line 283, in wait\n",
      "    found, abandoned = self._slot._get_and_clear(timeout=wait_timeout)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py\", line 130, in _get_and_clear\n",
      "    if self._wait(timeout=timeout):\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py\", line 126, in _wait\n",
      "    return self._event.wait(timeout=timeout)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/threading.py\", line 558, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/Users/henrismidt/anaconda3/envs/alzheimer/lib/python3.8/threading.py\", line 306, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "Exception\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alzheimer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
